{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"After a five year struggle, creditors of the collapsed, fraud-ridden BCCI will receive a payment of $2.65 billion on Tuesday, equal to 24.5 percent of their claims, a spokesman for the liquidators said on Monday.\\nBank of Credit and Commerce International, founded in 1972, was closed by central banks in 1991 and collapsed with debts of more than $12 billion when evidence of massive fraud and money laundering was unearthed leading to a tangled web of litigation which shows no sign of reaching an early conclusion.\\nBCCI had assets of $24 billion and operations in 71 countries at the time of its collapse.\\nLiquidator Deloitte and Touche said a further payment, reportedly of 10 percent, of the admitted claims which total some $10.5 billion should be made in the next 12 to 16 months.\\nThe gross fund of amounts recovered by the liquidators stands at around $4.0 billion and includes $1.5 billion paid by BCCI's majority shareholder, the government of Abu Dhabi, which will pay a further $250 million in due course following a settlement reached earlier this year.\\nThis, in addition to efforts by US authorities which resulted in the recovery of more than $500 million from the United States paved the way for the first dividend payment.\\nA further $245 million was paid by Saudi billionaire Sheikh Khalid bin Mahfouz who the liquidators alleged was involved in covering up the BCCI scandal. Under a 1995 Luxembourg court settlement, Mahfouz agreed to pay without admitting liability, in return for the lawsuits being dropped.\\nThe liquidators still have outstanding claims against the Bank of England, the Institut Monetaire Luxembourgeois (BCCI's operations were based in Luxembourgh) and the auditors of the bank, international accountancy firms Price Waterhouse and Ernst &amp; Whinney, now part of the merged Ernst &amp; Young.\\nPrice Waterhouse has said it is making a multi-billion dollar counter claim against Abu Dhabi.\\nFurther law suits are also pending around the world in an attempt to recover further amounts.\\nThe two biggest groups of creditors of BCCI are in the United Arab Emirates (UAE) and in Britain.\\nThe English liquidators of BCCI, Deloite &amp; Touche, have recovered over $1 billion and have been paid a massive $200 million in fees.\\nIn a report to the High Court earlier this year, the liquidator said legal fees in the liquidation ammounted to over $75 million so far.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "Text = open('../data/C50train/JoeOrtiz/242939newsML.txt').read()\n",
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 1 \n",
    "***\n",
    "Perform a sentence tokenization on the above data using `sent_tokenize()` and store it in a variable called '**Sent**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "Sent = nltk.sent_tokenize(Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 2 \n",
    "***\n",
    "- Iterate over every Sentence in the list **Sent**  using a for loop and convert every sentence into \n",
    "    - lower case \n",
    "    - and then tokenize it using the instantiated object \n",
    "- Now remove the stopwords from the tokens \n",
    "- Lemmatize them using `WordNetLemmatizer()` \n",
    "- Finally append them into the list called **Texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['five', 'year', 'struggle', 'creditor', 'collapsed', 'fraud', 'ridden', 'bcci', 'receive', 'payment', '2', '65', 'billion', 'tuesday', 'equal', '24', '5', 'percent', 'claim', 'spokesman', 'liquidator', 'said', 'monday'], ['bank', 'credit', 'commerce', 'international', 'founded', '1972', 'closed', 'central', 'bank', '1991', 'collapsed', 'debt', '12', 'billion', 'evidence', 'massive', 'fraud', 'money', 'laundering', 'unearthed', 'leading', 'tangled', 'web', 'litigation', 'show', 'sign', 'reaching', 'early', 'conclusion'], ['bcci', 'asset', '24', 'billion', 'operation', '71', 'country', 'time', 'collapse'], ['liquidator', 'deloitte', 'touche', 'said', 'payment', 'reportedly', '10', 'percent', 'admitted', 'claim', 'total', '10', '5', 'billion', 'made', 'next', '12', '16', 'month'], ['gross', 'fund', 'amount', 'recovered', 'liquidator', 'stand', 'around', '4', '0', 'billion', 'includes', '1', '5', 'billion', 'paid', 'bcci', 'majority', 'shareholder', 'government', 'abu', 'dhabi', 'pay', '250', 'million', 'due', 'course', 'following', 'settlement', 'reached', 'earlier', 'year'], ['addition', 'effort', 'u', 'authority', 'resulted', 'recovery', '500', 'million', 'united', 'state', 'paved', 'way', 'first', 'dividend', 'payment'], ['245', 'million', 'paid', 'saudi', 'billionaire', 'sheikh', 'khalid', 'bin', 'mahfouz', 'liquidator', 'alleged', 'involved', 'covering', 'bcci', 'scandal'], ['1995', 'luxembourg', 'court', 'settlement', 'mahfouz', 'agreed', 'pay', 'without', 'admitting', 'liability', 'return', 'lawsuit', 'dropped'], ['liquidator', 'still', 'outstanding', 'claim', 'bank', 'england', 'institut', 'monetaire', 'luxembourgeois', 'bcci', 'operation', 'based', 'luxembourgh', 'auditor', 'bank', 'international', 'accountancy', 'firm', 'price', 'waterhouse', 'ernst', 'amp', 'whinney', 'part', 'merged', 'ernst', 'amp', 'young'], ['price', 'waterhouse', 'said', 'making', 'multi', 'billion', 'dollar', 'counter', 'claim', 'abu', 'dhabi'], ['law', 'suit', 'also', 'pending', 'around', 'world', 'attempt', 'recover', 'amount'], ['two', 'biggest', 'group', 'creditor', 'bcci', 'united', 'arab', 'emirate', 'uae', 'britain'], ['english', 'liquidator', 'bcci', 'deloite', 'amp', 'touche', 'recovered', '1', 'billion', 'paid', 'massive', '200', 'million', 'fee'], ['report', 'high', 'court', 'earlier', 'year', 'liquidator', 'said', 'legal', 'fee', 'liquidation', 'ammounted', '75', 'million', 'far']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "en_stop = set(stopwords.words('english'))\n",
    "\n",
    "Lema = WordNetLemmatizer()\n",
    "\n",
    "Texts = []\n",
    "\n",
    "for i in Sent:\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    lemmatized_tokens = [Lema.lemmatize(i) for i in stopped_tokens]\n",
    "    Texts.append(lemmatized_tokens)\n",
    "    \n",
    "print(Texts)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 3 \n",
    "***\n",
    "Using the method `.Dictionary()` inside the module `corpora` to create a unique token for every word and also print out the tokens assigned respectively using the `.token2id` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(171 unique tokens: ['2', '24', '5', '65', 'bcci']...)\n",
      "{'2': 0, '24': 1, '5': 2, '65': 3, 'bcci': 4, 'billion': 5, 'claim': 6, 'collapsed': 7, 'creditor': 8, 'equal': 9, 'five': 10, 'fraud': 11, 'liquidator': 12, 'monday': 13, 'payment': 14, 'percent': 15, 'receive': 16, 'ridden': 17, 'said': 18, 'spokesman': 19, 'struggle': 20, 'tuesday': 21, 'year': 22, '12': 23, '1972': 24, '1991': 25, 'bank': 26, 'central': 27, 'closed': 28, 'commerce': 29, 'conclusion': 30, 'credit': 31, 'debt': 32, 'early': 33, 'evidence': 34, 'founded': 35, 'international': 36, 'laundering': 37, 'leading': 38, 'litigation': 39, 'massive': 40, 'money': 41, 'reaching': 42, 'show': 43, 'sign': 44, 'tangled': 45, 'unearthed': 46, 'web': 47, '71': 48, 'asset': 49, 'collapse': 50, 'country': 51, 'operation': 52, 'time': 53, '10': 54, '16': 55, 'admitted': 56, 'deloitte': 57, 'made': 58, 'month': 59, 'next': 60, 'reportedly': 61, 'total': 62, 'touche': 63, '0': 64, '1': 65, '250': 66, '4': 67, 'abu': 68, 'amount': 69, 'around': 70, 'course': 71, 'dhabi': 72, 'due': 73, 'earlier': 74, 'following': 75, 'fund': 76, 'government': 77, 'gross': 78, 'includes': 79, 'majority': 80, 'million': 81, 'paid': 82, 'pay': 83, 'reached': 84, 'recovered': 85, 'settlement': 86, 'shareholder': 87, 'stand': 88, '500': 89, 'addition': 90, 'authority': 91, 'dividend': 92, 'effort': 93, 'first': 94, 'paved': 95, 'recovery': 96, 'resulted': 97, 'state': 98, 'u': 99, 'united': 100, 'way': 101, '245': 102, 'alleged': 103, 'billionaire': 104, 'bin': 105, 'covering': 106, 'involved': 107, 'khalid': 108, 'mahfouz': 109, 'saudi': 110, 'scandal': 111, 'sheikh': 112, '1995': 113, 'admitting': 114, 'agreed': 115, 'court': 116, 'dropped': 117, 'lawsuit': 118, 'liability': 119, 'luxembourg': 120, 'return': 121, 'without': 122, 'accountancy': 123, 'amp': 124, 'auditor': 125, 'based': 126, 'england': 127, 'ernst': 128, 'firm': 129, 'institut': 130, 'luxembourgeois': 131, 'luxembourgh': 132, 'merged': 133, 'monetaire': 134, 'outstanding': 135, 'part': 136, 'price': 137, 'still': 138, 'waterhouse': 139, 'whinney': 140, 'young': 141, 'counter': 142, 'dollar': 143, 'making': 144, 'multi': 145, 'also': 146, 'attempt': 147, 'law': 148, 'pending': 149, 'recover': 150, 'suit': 151, 'world': 152, 'arab': 153, 'biggest': 154, 'britain': 155, 'emirate': 156, 'group': 157, 'two': 158, 'uae': 159, '200': 160, 'deloite': 161, 'english': 162, 'fee': 163, '75': 164, 'ammounted': 165, 'far': 166, 'high': 167, 'legal': 168, 'liquidation': 169, 'report': 170}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(Texts)\n",
    "print(dictionary)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 4 \n",
    "***\n",
    "Now convert the dictionary into a bag of words list using the `.doc2bow()` method in `dictionary` and store it in a variable **corpus** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]\n",
      "[(5, 1), (7, 1), (11, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1)]\n",
      "[(1, 1), (4, 1), (5, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1)]\n",
      "[(2, 1), (5, 1), (6, 1), (12, 1), (14, 1), (15, 1), (18, 1), (23, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1)]\n",
      "[(2, 1), (4, 1), (5, 2), (12, 1), (22, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1)]\n",
      "[(14, 1), (81, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1)]\n",
      "[(4, 1), (12, 1), (81, 1), (82, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1)]\n",
      "[(83, 1), (86, 1), (109, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1)]\n",
      "[(4, 1), (6, 1), (12, 1), (26, 2), (36, 1), (52, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 2), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1)]\n",
      "[(5, 1), (6, 1), (18, 1), (68, 1), (72, 1), (137, 1), (139, 1), (142, 1), (143, 1), (144, 1), (145, 1)]\n",
      "[(69, 1), (70, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1)]\n",
      "[(4, 1), (8, 1), (100, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1)]\n",
      "[(4, 1), (5, 1), (12, 1), (40, 1), (63, 1), (65, 1), (81, 1), (82, 1), (85, 1), (124, 1), (160, 1), (161, 1), (162, 1), (163, 1)]\n",
      "[(12, 1), (18, 1), (22, 1), (74, 1), (81, 1), (116, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in Texts]\n",
    "for line in corpus:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 5 \n",
    "***\n",
    "Create an LDA model with number of topics as 5 of your choice and your choice of total passes. Now print out the top 5 topics and also the top 3 words in every topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=171, num_topics=5, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word = dictionary, passes=20)\n",
    "\n",
    "print(ldamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.025*\"billion\" + 0.025*\"settlement\" + 0.025*\"amount\"')\n",
      "(1, '0.034*\"bank\" + 0.026*\"liquidator\" + 0.018*\"amp\"')\n",
      "(2, '0.030*\"million\" + 0.030*\"bcci\" + 0.030*\"united\"')\n",
      "(3, '0.040*\"bcci\" + 0.040*\"billion\" + 0.027*\"liquidator\"')\n",
      "(4, '0.027*\"said\" + 0.027*\"waterhouse\" + 0.027*\"price\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamodel.print_topics(num_topics=5, num_words=3):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
